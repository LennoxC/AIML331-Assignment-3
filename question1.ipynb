{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AIML331 Assignment 3\n",
    "### crowelenn, 300607096\n",
    "\n",
    "In this assignment, we focus on using modern machine learning techniques to classify animals from the OxfordIIITPet dataset. The animals are to be classified into the following categories:\n",
    "\n",
    "- long-haired cat\n",
    "- short-haired cat\n",
    "- long-haired dog\n",
    "- short-haired dog\n",
    "\n",
    "In the first part of the assignment, we will train and evaluate a convolutional neural network to perform this task."
   ],
   "id": "bfc6c8d4e96e1e19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Setup\n",
    "Import libraries, and load the dataset. The function to load the dataset has been provided in `dataset_wrapper` and the data is stored in the `./data` local directory."
   ],
   "id": "2d928d4a05cd3671"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T01:24:51.660166Z",
     "start_time": "2025-05-18T01:24:24.488045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_wrapper import get_pet_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:12.436887Z",
     "start_time": "2025-05-16T01:36:40.156056Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset, val_dataset, test_dataset = get_pet_datasets(img_width=128, img_height=128,root_path='./data' )",
   "id": "123698bd9c4d206",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:12.638202Z",
     "start_time": "2025-05-16T01:37:12.631990Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Loaded data, train = {len(train_dataset)}, test = {len(test_dataset)}\")",
   "id": "35997bf2379270b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data, train = 5719, test = 716\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the required libraries:",
   "id": "11f07191455d7f0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:13.964112Z",
     "start_time": "2025-05-16T01:37:12.646441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check that cuda is working\n",
    "torch.cuda.is_available()"
   ],
   "id": "8293db5e150cb795",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Dataloaders, training devices etc\n",
    "All the pytorch stuff that isn't the neural network itself"
   ],
   "id": "1d9d18114fd4a07c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:13.976659Z",
     "start_time": "2025-05-16T01:37:13.971425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the compute device\n",
    "compute_device = torch.device('cuda:0')"
   ],
   "id": "f27c9fd69e39b810",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:14.002122Z",
     "start_time": "2025-05-16T01:37:13.994900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the datasets\n",
    "batch_size = 64\n",
    "training_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testing_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "6fa72c20ee844705",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Defining the neural network\n",
    "\n",
    "**Task 1**:  Build a CNN architecture from scratch using PyTorch. You may utilise basic layers and components provided by PyTorch (e.g., Conv2D, BatchNorm2D, MaxPool2D, Linear, ReLU), but you are required to design and assemble the overall model architecture (including the loss function) independently"
   ],
   "id": "6f3cd2d21205bb73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:14.017308Z",
     "start_time": "2025-05-16T01:37:14.007346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PetsConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(PetsConvNet, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,\n",
    "                      out_channels=16,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l1 output dim = 128 - 5 + 1 + 2*2 / 2\n",
    "        #               = 64\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l2 output dim = 64 - 5 + 1 + 2*2 / 2\n",
    "        #               = 32\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l3 output dim = 32 - 5 + 1 + 2*2 / 2\n",
    "        #               = 16\n",
    "\n",
    "        self.fc = nn.Linear(16*16*64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "id": "3d9f16d5e1d6a198",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Functions for training & testing",
   "id": "c85c6aacd63b0e62"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:14.040825Z",
     "start_time": "2025-05-16T01:37:14.026922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_training(model, experiment_name, criterion, optimizer, num_epochs=20, patience=5):\n",
    "    writer = SummaryWriter('runs/'+experiment_name)\n",
    "\n",
    "    min_validation_loss = None\n",
    "    best_model_state = None # store the best model here. Re-instate this if early stopping is triggered\n",
    "    wait = 0\n",
    "\n",
    "    # make sure the model is starting with new weights\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    steps = len(training_dataloader)\n",
    "    for epoch in range(num_epochs): # epoch iteration loop\n",
    "        model.train()\n",
    "        train_loss_epoch_total = 0\n",
    "        batches_count = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(training_dataloader):\n",
    "\n",
    "            if i == 0:\n",
    "                writer.add_graph(model, images.to(compute_device))\n",
    "            images = images.to(compute_device)\n",
    "            labels = labels.to(compute_device)\n",
    "\n",
    "            # forwards\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backpropogation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_epoch_total += loss.item()\n",
    "            batches_count += 1\n",
    "\n",
    "        train_loss = train_loss_epoch_total / batches_count\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch+1)\n",
    "\n",
    "        # validation accuracy\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_loss_epoch_total = 0\n",
    "            val_batches_count = 0\n",
    "\n",
    "            for images, labels in validation_dataloader:\n",
    "                images = images.to(compute_device)\n",
    "                labels = labels.to(compute_device)\n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss_epoch_total += val_loss.item()\n",
    "                val_batches_count += 1\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        val_loss = val_loss_epoch_total / val_batches_count\n",
    "\n",
    "        writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "        writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "\n",
    "        if min_validation_loss is None or val_loss < min_validation_loss:\n",
    "            min_validation_loss = val_loss\n",
    "            best_model_state = model.state_dict() # save the best weights\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        if wait >= patience:\n",
    "            break # exit early if there has been no improvement in validation loss\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Best model weights restored.\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    return model"
   ],
   "id": "9169878aba104c0d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:14.056366Z",
     "start_time": "2025-05-16T01:37:14.048891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_testing(model, dataloader):\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(compute_device)\n",
    "            labels = labels.to(compute_device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "        return accuracy, 'Accuracy of the model on the provided images: {} %'.format(accuracy)\n"
   ],
   "id": "8e63274732ef50a2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Task 2** Train the model for a few epochs until the loss value stabilises or flattens, indicating convergence (normally within 20 epochs for this dataset)",
   "id": "ceae555c85a4ae58"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:37:14.623684Z",
     "start_time": "2025-05-16T01:37:14.064908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_model = PetsConvNet(num_classes=4).to(compute_device)\n",
    "weights = [600/7149, 1771/7149, 2590/7149, 2188/7149]\n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=0.01)"
   ],
   "id": "b5f818d7a2ff305f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:40:48.136054Z",
     "start_time": "2025-05-16T01:37:14.775888Z"
    }
   },
   "cell_type": "code",
   "source": "baseline_model_trained = do_training(baseline_model, experiment_name='cnn_baseline', criterion=criterion, optimizer=optimizer, num_epochs=50, patience=10)",
   "id": "7e08c03a5ac84eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:40:49.156980Z",
     "start_time": "2025-05-16T01:40:48.266277Z"
    }
   },
   "cell_type": "code",
   "source": "acc, acc_string = do_testing(baseline_model_trained, validation_dataloader)",
   "id": "ef5a35aecf3c2509",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:40:49.186359Z",
     "start_time": "2025-05-16T01:40:49.175006Z"
    }
   },
   "cell_type": "code",
   "source": "print(acc_string)",
   "id": "3043e522c7b875f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 46.9187675070028 %\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The baseline model achieves a test accuracy of 49.72%. This is good considering training the model from scratch on only ~5000 images.\n",
    "\n",
    "### Experiments\n",
    "In the `cnn_models` file I have defined the following classes:\n",
    "\n",
    "- PetsConvNetBaseline - this was defined in the question1.ipynb\n",
    "- PetsConvNetNoBatchNorm - baseline without batch normalization\n",
    "- PetsConvNetLeakyRelu - baseline with a leakyReLU activation function\n",
    "- PetsConvNetGelu - baseline with a GELU activation function\n",
    "- PetsConvNetL5 - baseline with 5 layers\n",
    "- PetsConvNetL7 - baseline with 7 layers\n",
    "\n",
    "Each of these will be trained & evaluated with the functions above to fairly compare their performance."
   ],
   "id": "be5a98f15b0995a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:40:49.285059Z",
     "start_time": "2025-05-16T01:40:49.263349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cnn_models import PetsConvNetNoBatchNorm, PetsConvNetLeakyRelu, PetsConvNetGelu, PetsConvNetL5, PetsConvNetL7\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "learningrate = 0.01\n",
    "epochs = 50\n",
    "patience = 10"
   ],
   "id": "cf293cafed1e8a5a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### No Batch Normalization",
   "id": "9452afa8e4ae85f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:44:11.737923Z",
     "start_time": "2025-05-16T01:40:49.321203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nobatchnorm_model = PetsConvNetNoBatchNorm(num_classes=4).to(compute_device)\n",
    "optimizer = torch.optim.Adam(nobatchnorm_model.parameters(), lr=learningrate)\n",
    "\n",
    "nobatchnorm_model_trained = do_training(nobatchnorm_model, experiment_name='cnn_no_batchnorm', criterion=criterion, optimizer=optimizer, num_epochs=epochs, patience=patience)\n",
    "acc, acc_string = do_testing(nobatchnorm_model_trained, validation_dataloader)\n",
    "print(acc_string)"
   ],
   "id": "39087fe02761e1c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n",
      "Accuracy of the model on the provided images: 34.593837535014 %\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Leaky ReLU",
   "id": "36d276cb9fda814e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:47:42.909258Z",
     "start_time": "2025-05-16T01:44:11.808654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "leakyrelu_model = PetsConvNetLeakyRelu(num_classes=4).to(compute_device)\n",
    "optimizer = torch.optim.Adam(leakyrelu_model.parameters(), lr=learningrate)\n",
    "\n",
    "leakyrelu_model_trained = do_training(leakyrelu_model, experiment_name='cnn_leaky_relu', criterion=criterion, optimizer=optimizer, num_epochs=epochs, patience=patience)\n",
    "acc, acc_string = do_testing(leakyrelu_model_trained, validation_dataloader)\n",
    "print(acc_string)"
   ],
   "id": "6d8ef4e295b4c17a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n",
      "Accuracy of the model on the provided images: 45.65826330532213 %\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GELU",
   "id": "bcdf2c3c2652d2dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:51:27.760728Z",
     "start_time": "2025-05-16T01:47:42.954586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gelu_model = PetsConvNetGelu(num_classes=4).to(compute_device)\n",
    "optimizer = torch.optim.Adam(gelu_model.parameters(), lr=learningrate)\n",
    "\n",
    "gelu_model_trained = do_training(gelu_model, experiment_name='cnn_gelu', criterion=criterion, optimizer=optimizer, num_epochs=epochs, patience=patience)\n",
    "acc, acc_string = do_testing(gelu_model_trained, validation_dataloader)\n",
    "print(acc_string)"
   ],
   "id": "6f0b1c4f6ab8dba7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n",
      "Accuracy of the model on the provided images: 47.05882352941177 %\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5 Layers",
   "id": "259b1339f600cce9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T01:58:00.703223Z",
     "start_time": "2025-05-16T01:51:27.815811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "L5_model = PetsConvNetL5(num_classes=4).to(compute_device)\n",
    "optimizer = torch.optim.Adam(L5_model.parameters(), lr=learningrate)\n",
    "\n",
    "L5_model_trained = do_training(L5_model, experiment_name='cnn_L5', criterion=criterion, optimizer=optimizer, num_epochs=epochs, patience=patience)\n",
    "acc, acc_string = do_testing(L5_model_trained, validation_dataloader)\n",
    "print(acc_string)"
   ],
   "id": "86240e753d7c90fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n",
      "Accuracy of the model on the provided images: 51.680672268907564 %\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 7 Layers",
   "id": "4fff74062dd7a77a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:06:07.265756Z",
     "start_time": "2025-05-16T01:58:00.756197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "L7_model = PetsConvNetL7(num_classes=4).to(compute_device)\n",
    "optimizer = torch.optim.Adam(L7_model.parameters(), lr=learningrate)\n",
    "\n",
    "L7_model_trained = do_training(L7_model, experiment_name='cnn_L7', criterion=criterion, optimizer=optimizer, num_epochs=epochs, patience=patience)\n",
    "acc, acc_string = do_testing(L7_model_trained, validation_dataloader)\n",
    "print(acc_string)"
   ],
   "id": "8ab2f1989b9de1eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n",
      "Accuracy of the model on the provided images: 56.72268907563025 %\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Residual Integration\n",
    "Modify your CNN architecture to incorporate a residual connection around the CNN layer. Specifically, instead of computing the output as CNN(x), the modified network should compute the output as x + CNN(x), enabling the model to learn residual mappings.\n",
    "\n",
    "I decided it would make most sense to re-build the 7-layer CNN with skip connections, as this has the most parameters and is most likely to overfit."
   ],
   "id": "461907d236be4466"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T05:03:54.619419Z",
     "start_time": "2025-05-16T05:03:54.612406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the network with skip connections is going to be made up of these\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, downsample=False):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "\n",
    "        pooling_factor = 2 if downsample else 1 # downsample by a factor of 2\n",
    "        padding = (kernel_size - 1) // 2\n",
    "\n",
    "        self.convolution1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=out_channels,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      stride=pooling_factor,\n",
    "                                      padding=padding,\n",
    "                                      bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.BatchNorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample_skip = None\n",
    "\n",
    "        # if we are downsampling or changing the number of channels,\n",
    "        #   then we will need to apply this to the x 'skip connection'\n",
    "        #   input too, otherwise the piecewise addition will fail\n",
    "        if downsample or in_channels != out_channels:\n",
    "            self.downsample_skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels,\n",
    "                          out_channels=out_channels,\n",
    "                          kernel_size=1,\n",
    "                          stride=pooling_factor,\n",
    "                          bias=False), # BatchNorm has a bias so this is redundant\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x # save the original input here\n",
    "\n",
    "        # push the input through the 'regular' CNN components\n",
    "        out = self.BatchNorm(self.relu(self.convolution1(x)))\n",
    "        #out = self.relu(self.BatchNorm(self.convolution1(x)))\n",
    "\n",
    "        # I could add more batch normalization?\n",
    "\n",
    "        # if downsampling, then this will be defined. The input needs to be transformed\n",
    "        if self.downsample_skip is not None:\n",
    "            input = self.downsample_skip(x)\n",
    "\n",
    "        # piecewise addition for the skip connection\n",
    "        out += input\n",
    "\n",
    "        # experimental\n",
    "        out = self.relu2(self.BatchNorm2(out))\n",
    "\n",
    "        return out\n"
   ],
   "id": "cb24adf6df0a7d68",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T04:47:01.926955Z",
     "start_time": "2025-05-16T04:47:01.910647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PetsConvNetSkipConnectionL3(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(PetsConvNetSkipConnectionL3, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,\n",
    "                      out_channels=16,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l1 output dim = 128 - 5 + 1 + 2*2 / 2\n",
    "        #               = 64\n",
    "        self.layer2 = ResNetBlock(16, 32, kernel_size=5, downsample=True)\n",
    "        # l2 output dim = 32\n",
    "\n",
    "        self.layer3 = ResNetBlock(32, 64, kernel_size=5, downsample=True)\n",
    "        # l3 output dim = 16\n",
    "\n",
    "        self.fc = nn.Linear(16*16*64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "id": "89872e78b247c080",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T05:03:57.408783Z",
     "start_time": "2025-05-16T05:03:57.401782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PetsConvNetSkipConnectionL7(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(PetsConvNetSkipConnectionL7, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,\n",
    "                      out_channels=16,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l1 output dim = 128 - 5 + 1 + 2*2 / 2\n",
    "        #               = 64\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l2 output dim = 64 - 5 + 1 + 2*2 / 2\n",
    "        #               = 32\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l3 output dim = 32 - 5 + 1 + 2*2 / 2\n",
    "        #               = 16\n",
    "\n",
    "        # push through layers 4 & 5 before pooling\n",
    "        # keep channel at 64 until layer 5\n",
    "        # use 3x3 convolutions as the inputs are only 16x16 now\n",
    "\n",
    "        self.layer4 = ResNetBlock(64, 64, kernel_size=3, downsample=False)\n",
    "        # l4 output dim = 16\n",
    "\n",
    "        self.layer5 = ResNetBlock(64, 128, kernel_size=3, downsample=True)\n",
    "        # l5 output dim = 8\n",
    "\n",
    "        self.layer6 = ResNetBlock(128, 128, kernel_size=3, downsample=False)\n",
    "        # l6 output dim = 8\n",
    "\n",
    "        self.layer7 = ResNetBlock(128, 256, kernel_size=3, downsample=True)\n",
    "        # l7 output dim = 4\n",
    "\n",
    "        self.fc = nn.Linear(4 * 4 * 256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "id": "75ad5c9ba663fa06",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T04:48:40.732057Z",
     "start_time": "2025-05-16T04:47:32.950454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "L3_skipconnection_model = PetsConvNetSkipConnectionL3(num_classes=4).to(compute_device)\n",
    "optimizer = torch.optim.Adam(L3_skipconnection_model.parameters(), lr=learningrate)\n",
    "\n",
    "L3_skipconnection_model_trained = do_training(L3_skipconnection_model, experiment_name='cnn_skip_L3', criterion=criterion, optimizer=optimizer, num_epochs=epochs)\n",
    "acc, acc_string = do_testing(L3_skipconnection_model_trained, validation_dataloader)\n",
    "print(acc_string)"
   ],
   "id": "3e65925e8363516a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n",
      "Accuracy of the model on the provided images: 34.173669467787114 %\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T05:12:18.661096Z",
     "start_time": "2025-05-16T05:08:39.337943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "L7_skipconnection_model = PetsConvNetSkipConnectionL7(num_classes=4).to(compute_device)\n",
    "optimizer = torch.optim.Adam(L7_skipconnection_model.parameters(), lr=learningrate)\n",
    "\n",
    "L7_skipconnection_model_trained = do_training(L7_skipconnection_model, experiment_name='cnn_skip_L7', criterion=criterion, optimizer=optimizer, num_epochs=50, patience=10)\n",
    "acc, acc_string = do_testing(L7_skipconnection_model_trained, validation_dataloader)\n",
    "print(acc_string)"
   ],
   "id": "18f4761ad4697e7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n",
      "Accuracy of the model on the provided images: 43.13725490196079 %\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Final Model Testing\n",
    "Until now, the models have only been evaluated on the validation set. They should be evaluated on the Testing set to assess their generalisation performance."
   ],
   "id": "efa0acba2324bdd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:51.747527Z",
     "start_time": "2025-05-16T02:12:50.602366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Baseline Model\n",
    "print(do_testing(baseline_model_trained, testing_dataloader)[1])"
   ],
   "id": "7d37f643bae7c61a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 49.16201117318436 %\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:52.587207Z",
     "start_time": "2025-05-16T02:12:51.803715Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_testing(nobatchnorm_model_trained, testing_dataloader)[1])",
   "id": "4ce152d5a77ec635",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 39.245810055865924 %\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:54.281939Z",
     "start_time": "2025-05-16T02:12:52.598699Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_testing(leakyrelu_model_trained, testing_dataloader)[1])",
   "id": "c2b264958ead4526",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 50.977653631284916 %\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:55.150960Z",
     "start_time": "2025-05-16T02:12:54.306794Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_testing(gelu_model_trained, testing_dataloader)[1])",
   "id": "70c7b78adca9dc69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 47.90502793296089 %\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:56.081753Z",
     "start_time": "2025-05-16T02:12:55.191880Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_testing(L5_model_trained, testing_dataloader)[1])",
   "id": "187329882c8105e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 52.23463687150838 %\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:57.006686Z",
     "start_time": "2025-05-16T02:12:56.089005Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_testing(L7_model_trained, testing_dataloader)[1])",
   "id": "b8e86bb5f8eda8da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 56.28491620111732 %\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:57.910028Z",
     "start_time": "2025-05-16T02:12:57.033747Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_testing(L3_skipconnection_model_trained, testing_dataloader)[1])",
   "id": "f52b45be1209e9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 43.99441340782123 %\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T02:12:58.872910Z",
     "start_time": "2025-05-16T02:12:57.930319Z"
    }
   },
   "cell_type": "code",
   "source": "print(do_testing(L7_skipconnection_model_trained, testing_dataloader)[1])",
   "id": "3ae40e6fc7d961ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 49.16201117318436 %\n"
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
