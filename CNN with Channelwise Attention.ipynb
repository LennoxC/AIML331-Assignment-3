{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# CNN with Channel-wise Attention\n",
    "\n",
    "- Modify a standard CNN by inserting channel-wise attention modules at suitable\n",
    "locations.\n",
    "\n",
    "#### Setup\n",
    "Import libraries, and load the dataset. The function to load the dataset has been provided in `dataset_wrapper` and the data is stored in the `./data` local directory.\n"
   ],
   "id": "88191eea976f872d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T04:28:38.566272Z",
     "start_time": "2025-05-24T04:28:08.730055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataset_wrapper import get_pet_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from question1 import acc_string"
   ],
   "id": "fad1c7622aa481b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T04:29:35.431103Z",
     "start_time": "2025-05-24T04:28:51.255145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset, val_dataset, test_dataset = get_pet_datasets(img_width=128, img_height=128,root_path='./data' )\n",
    "print(f\"Loaded data, train = {len(train_dataset)}, test = {len(test_dataset)}\")"
   ],
   "id": "fb6b71a93a1ae1a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data, train = 5719, test = 716\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T04:29:36.820576Z",
     "start_time": "2025-05-24T04:29:35.443644Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "63e0cfb53044c4d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T04:29:36.943127Z",
     "start_time": "2025-05-24T04:29:36.936093Z"
    }
   },
   "cell_type": "code",
   "source": "compute_device = torch.device('cuda:0')",
   "id": "778ac3f56b52434e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the Data-loaders",
   "id": "d1b91607195c10e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T04:29:36.976170Z",
     "start_time": "2025-05-24T04:29:36.967624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the datasets\n",
    "batch_size = 64\n",
    "training_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testing_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "bf9322d8f589fb31",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Defining the Neural Network\n",
    "This is based off a baseline CNN architecture with five layers.\n",
    "\n",
    "The implementation is inspired by this source: https://medium.com/@simonyihunie/a-comprehensive-guide-to-attention-mechanisms-in-cnns-from-intuition-to-implementation-7a40df01a118"
   ],
   "id": "e4d3796ae443ac9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T04:29:37.004622Z",
     "start_time": "2025-05-24T04:29:36.986728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelwiseAttention(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super().__init__()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fullyConnected = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.pooling(x).view(b, c)\n",
    "        y = self.fullyConnected(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ],
   "id": "ac0ddf05bd4634f7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T05:01:15.420804Z",
     "start_time": "2025-05-24T05:01:15.405530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChannelWiseCNN(nn.Module):\n",
    "    def __init__(self, classes=4, in_channels=3, reduction=4):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l1 output dim = 128 - 5 + 1 + 2*2 / 2\n",
    "        #               = 64\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l2 output dim = 64 - 5 + 1 + 2*2 / 2\n",
    "        #               = 32\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # l3 output dim = 32 - 5 + 1 + 2*2 / 2\n",
    "        #               = 16\n",
    "\n",
    "        self.ChannelAttention = ChannelwiseAttention(channel=64, reduction=reduction)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, 64, kernel_size=1),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),  # 128 → 64\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),  # 64 → 32\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),  # 32 → 16\n",
    "                nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=64, out_features=classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the paper has a skip connection around the whole block\n",
    "        original_input = x\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.ChannelAttention(x)\n",
    "\n",
    "        residual = self.relu(self.skip(original_input))\n",
    "\n",
    "        x = x + residual\n",
    "\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # pass through the fully connected layer for classification\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ],
   "id": "4bffb6f7d7629974",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Testing",
   "id": "20ca65f08df5cee5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T05:01:17.897593Z",
     "start_time": "2025-05-24T05:01:17.889173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def do_training(model, experiment_name, criterion, optimizer, num_epochs=20, patience=5):\n",
    "    writer = SummaryWriter('runs/' + experiment_name)\n",
    "\n",
    "    min_validation_loss = None\n",
    "    best_model_state = None  # store the best model here. Re-instate this if early stopping is triggered\n",
    "    wait = 0\n",
    "\n",
    "    # make sure the model is starting with new weights\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    steps = len(training_dataloader)\n",
    "    for epoch in range(num_epochs):  # epoch iteration loop\n",
    "        model.train()\n",
    "        train_loss_epoch_total = 0\n",
    "        batches_count = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(training_dataloader):\n",
    "\n",
    "            if i == 0:\n",
    "                writer.add_graph(model, images.to(compute_device))\n",
    "            images = images.to(compute_device)\n",
    "            labels = labels.to(compute_device)\n",
    "\n",
    "            # forwards\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backpropogation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_epoch_total += loss.item()\n",
    "            batches_count += 1\n",
    "\n",
    "        train_loss = train_loss_epoch_total / batches_count\n",
    "        writer.add_scalar('Loss/train', train_loss, epoch + 1)\n",
    "\n",
    "        # validation accuracy\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            val_loss_epoch_total = 0\n",
    "            val_batches_count = 0\n",
    "\n",
    "            for images, labels in validation_dataloader:\n",
    "                images = images.to(compute_device)\n",
    "                labels = labels.to(compute_device)\n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss_epoch_total += val_loss.item()\n",
    "                val_batches_count += 1\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        val_loss = val_loss_epoch_total / val_batches_count\n",
    "\n",
    "        writer.add_scalar('Accuracy/validation', val_acc, epoch)\n",
    "        writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "\n",
    "        if min_validation_loss is None or val_loss < min_validation_loss:\n",
    "            min_validation_loss = val_loss\n",
    "            best_model_state = model.state_dict()  # save the best weights\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        if wait >= patience:\n",
    "            break  # exit early if there has been no improvement in validation loss\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Best model weights restored.\")\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def do_testing(model, dataloader):\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(compute_device)\n",
    "            labels = labels.to(compute_device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "        return accuracy, 'Accuracy of the model on the provided images: {} %'.format(accuracy)"
   ],
   "id": "b3227676f0048e9b",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:27:34.275245Z",
     "start_time": "2025-05-24T08:27:34.262976Z"
    }
   },
   "cell_type": "code",
   "source": "channelwise_cnn = ChannelWiseCNN().to(compute_device)",
   "id": "9ac50323a0e719c9",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:27:34.832158Z",
     "start_time": "2025-05-24T08:27:34.825070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weights = [600/7149, 1771/7149, 2590/7149, 2188/7149]\n",
    "class_weights = torch.FloatTensor(weights).cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(channelwise_cnn.parameters(), lr=0.01)"
   ],
   "id": "56808c2cbbc25432",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T08:43:08.894482Z",
     "start_time": "2025-05-24T08:27:37.499584Z"
    }
   },
   "cell_type": "code",
   "source": "channelwise_cnn_trained = do_training(channelwise_cnn, experiment_name='channelwise_cnn', criterion=criterion, optimizer=optimizer, num_epochs=100, patience=10)",
   "id": "51156370ae4e243d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights restored.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T09:34:49.059910Z",
     "start_time": "2025-05-24T09:34:47.940199Z"
    }
   },
   "cell_type": "code",
   "source": "acc, acc_string = do_testing(channelwise_cnn_trained, testing_dataloader)",
   "id": "c5d0af593b9c8c6c",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T09:34:53.433629Z",
     "start_time": "2025-05-24T09:34:53.416569Z"
    }
   },
   "cell_type": "code",
   "source": "print(acc_string)",
   "id": "2f85e1b010bff645",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the provided images: 66.34078212290503 %\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dd790fe2b4001fc9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
